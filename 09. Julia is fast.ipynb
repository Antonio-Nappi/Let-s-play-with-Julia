{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia is fast\n",
    "\n",
    "Very often, benchmarks are used to compare languages.  These benchmarks can lead to long discussions, first as to exactly what is being benchmarked and secondly what explains the differences.  These simple questions can sometimes get more complicated than you at first might imagine.\n",
    "\n",
    "The purpose of this notebook is for you to see a simple benchmark for yourself.  One can read the notebook and see what happened on the author's Macbook Pro with a 4-core Intel Core I7, or run the notebook yourself.\n",
    "\n",
    "(This material began life as a wonderful lecture by Steven Johnson at MIT: https://github.com/stevengj/18S096/blob/master/lectures/lecture1/Boxes-and-registers.ipynb.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of this notebook\n",
    "\n",
    "- Define the sum function\n",
    "- Implementations & benchmarking of sum in...\n",
    "    - C (hand-written)\n",
    "    - C (hand-written with -ffast-math)\n",
    "    - python (built-in)\n",
    "    - python (numpy)\n",
    "    - python (hand-written)\n",
    "    - Julia (built-in)\n",
    "    - Julia (hand-written)\n",
    "    - Julia (hand-written with SIMD)\n",
    "- Summary of benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `sum`: An easy enough function to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the  **sum** function `sum(a)`, which computes\n",
    "$$\n",
    "\\mathrm{sum}(a) = \\sum_{i=1}^n a_i,\n",
    "$$\n",
    "where $n$ is the length of `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000-element Vector{Float64}:\n",
       " 0.4317568043478941\n",
       " 0.8566700130948739\n",
       " 0.9406424896027232\n",
       " 0.36100325801111155\n",
       " 0.9101263273874078\n",
       " 0.07114436142540148\n",
       " 0.32748490806439423\n",
       " 0.32440485955489406\n",
       " 0.28462320535763386\n",
       " 0.8187242345811767\n",
       " 0.09309836351456391\n",
       " 0.016853186912473728\n",
       " 0.15508663417261825\n",
       " ⋮\n",
       " 0.4085984931193385\n",
       " 0.2111478418116366\n",
       " 0.6452066713042888\n",
       " 0.33567792448352396\n",
       " 0.6789094653687731\n",
       " 0.02194182362210806\n",
       " 0.9572930967415654\n",
       " 0.41009686799635103\n",
       " 0.33173891369319586\n",
       " 0.654512724495752\n",
       " 0.7612263318280024\n",
       " 0.36612761261671256"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = rand(10^7) # 1D vector of random numbers, uniform on [0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.000566333321083e6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected result is 0.5 * 10^7, since the mean of each entry is 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking a few ways in a few languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.011696 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.000566333321083e6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.004769 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.000566333321083e6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.004699 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.000566333321083e6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `@time` macro can yield noisy results, so it's not our best choice for benchmarking!\n",
    "\n",
    "Luckily, Julia has a `BenchmarkTools.jl` package to make benchmarking easy and accurate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " using Pkg\n",
    "Pkg.add(\"BenchmarkTools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "using BenchmarkTools  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1. The C language\n",
    "\n",
    "C is often considered the gold standard: difficult on the human, nice for the machine. Getting within a factor of 2 of C is often satisfying. Nonetheless, even within C, there are many kinds of optimizations possible that a naive C writer may or may not get the advantage of.\n",
    "\n",
    "The current author does not speak C, so he does not read the cell below, but is happy to know that you can put C code in a Julia session, compile it, and run it. Note that the `\"\"\"` wrap a multi-line string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "IOError: could not spawn `gcc -fPIC -O3 -msse3 -xc -shared -o 'C:\\Users\\anton\\AppData\\Local\\Temp\\jl_Dnf5JhNdZs.dll' -`: no such file or directory (ENOENT)",
     "output_type": "error",
     "traceback": [
      "IOError: could not spawn `gcc -fPIC -O3 -msse3 -xc -shared -o 'C:\\Users\\anton\\AppData\\Local\\Temp\\jl_Dnf5JhNdZs.dll' -`: no such file or directory (ENOENT)",
      "",
      "Stacktrace:",
      "  [1] _spawn_primitive(file::String, cmd::Cmd, stdio::Vector{Any})",
      "    @ Base .\\process.jl:99",
      "  [2] #637",
      "    @ .\\process.jl:112 [inlined]",
      "  [3] setup_stdios(f::Base.var\"#637#638\"{Cmd}, stdios::Vector{Any})",
      "    @ Base .\\process.jl:196",
      "  [4] _spawn",
      "    @ .\\process.jl:111 [inlined]",
      "  [5] open(cmds::Cmd, stdio::Base.DevNull; write::Bool, read::Bool)",
      "    @ Base .\\process.jl:374",
      "  [6] open(cmds::Cmd, mode::String, stdio::Base.DevNull)",
      "    @ Base .\\process.jl:343",
      "  [7] open",
      "    @ .\\process.jl:338 [inlined]",
      "  [8] open(f::var\"#1#2\", cmds::Cmd, args::String; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ Base .\\process.jl:391",
      "  [9] open(f::Function, cmds::Cmd, args::String)",
      "    @ Base .\\process.jl:391",
      " [10] top-level scope",
      "    @ In[10]:19",
      " [11] eval",
      "    @ .\\boot.jl:360 [inlined]",
      " [12] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "using Libdl\n",
    "C_code = \"\"\"\n",
    "#include <stddef.h>\n",
    "double c_sum(size_t n, double *X) {\n",
    "    double s = 0.0;\n",
    "    for (size_t i = 0; i < n; ++i) {\n",
    "        s += X[i];\n",
    "    }\n",
    "    return s;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "const Clib = tempname()   # make a temporary file\n",
    "\n",
    "\n",
    "# compile to a shared library by piping C_code to gcc\n",
    "# (works only if you have gcc installed):\n",
    "\n",
    "open(`gcc -fPIC -O3 -msse3 -xc -shared -o $(Clib * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code) \n",
    "end\n",
    "\n",
    "# define a Julia function that calls the C function:\n",
    "c_sum(X::Array{Float64}) = ccall((\"c_sum\", Clib), Float64, (Csize_t, Ptr{Float64}), length(X), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: c_sum not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: c_sum not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[11]:1",
      " [2] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "c_sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: c_sum not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: c_sum not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[12]:1",
      " [2] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "c_sum(a) ≈ sum(a) # type \\approx and then <TAB> to get the ≈ symbolb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: c_sum not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: c_sum not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[13]:1",
      " [2] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "c_sum(a) - sum(a)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isapprox (generic function with 9 methods)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "≈  # alias for the `isapprox` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mx\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "isapprox(x, y; atol::Real=0, rtol::Real=atol>0 ? 0 : √eps, nans::Bool=false[, norm::Function])\n",
       "\\end{verbatim}\n",
       "Inexact equality comparison: \\texttt{true} if \\texttt{norm(x-y) <= max(atol, rtol*max(norm(x), norm(y)))}. The default \\texttt{atol} is zero and the default \\texttt{rtol} depends on the types of \\texttt{x} and \\texttt{y}. The keyword argument \\texttt{nans} determines whether or not NaN values are considered equal (defaults to false).\n",
       "\n",
       "For real or complex floating-point values, if an \\texttt{atol > 0} is not specified, \\texttt{rtol} defaults to the square root of \\href{@ref}{\\texttt{eps}} of the type of \\texttt{x} or \\texttt{y}, whichever is bigger (least precise). This corresponds to requiring equality of about half of the significand digits. Otherwise, e.g. for integer arguments or if an \\texttt{atol > 0} is supplied, \\texttt{rtol} defaults to zero.\n",
       "\n",
       "The \\texttt{norm} keyword defaults to \\texttt{abs} for numeric \\texttt{(x,y)} and to \\texttt{LinearAlgebra.norm} for arrays (where an alternative \\texttt{norm} choice is sometimes useful). When \\texttt{x} and \\texttt{y} are arrays, if \\texttt{norm(x-y)} is not finite (i.e. \\texttt{±Inf} or \\texttt{NaN}), the comparison falls back to checking whether all elements of \\texttt{x} and \\texttt{y} are approximately equal component-wise.\n",
       "\n",
       "The binary operator \\texttt{≈} is equivalent to \\texttt{isapprox} with the default arguments, and \\texttt{x ≉ y} is equivalent to \\texttt{!isapprox(x,y)}.\n",
       "\n",
       "Note that \\texttt{x ≈ 0} (i.e., comparing to zero with the default tolerances) is equivalent to \\texttt{x == 0} since the default \\texttt{atol} is \\texttt{0}.  In such cases, you should either supply an appropriate \\texttt{atol} (or use \\texttt{norm(x) ≤ atol}) or rearrange your code (e.g. use \\texttt{x ≈ y} rather than \\texttt{x - y ≈ 0}).   It is not possible to pick a nonzero \\texttt{atol} automatically because it depends on the overall scaling (the \"units\") of your problem: for example, in \\texttt{x - y ≈ 0}, \\texttt{atol=1e-9} is an absurdly small tolerance if \\texttt{x} is the \\href{https://en.wikipedia.org/wiki/Earth_radius}{radius of the Earth} in meters, but an absurdly large tolerance if \\texttt{x} is the \\href{https://en.wikipedia.org/wiki/Bohr_radius}{radius of a Hydrogen atom} in meters.\n",
       "\n",
       "\\begin{quote}\n",
       "\\textbf{compat}\n",
       "\n",
       "Julia 1.6\n",
       "\n",
       "Passing the \\texttt{norm} keyword argument when comparing numeric (non-array) arguments requires Julia 1.6 or later.\n",
       "\n",
       "\\end{quote}\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> 0.1 ≈ (0.1 - 1e-10)\n",
       "true\n",
       "\n",
       "julia> isapprox(10, 11; atol = 2)\n",
       "true\n",
       "\n",
       "julia> isapprox([10.0^9, 1.0], [10.0^9, 2.0])\n",
       "true\n",
       "\n",
       "julia> 1e-10 ≈ 0\n",
       "false\n",
       "\n",
       "julia> isapprox(1e-10, 0, atol=1e-8)\n",
       "true\n",
       "\\end{verbatim}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "isapprox(x; kwargs...) / ≈(x; kwargs...)\n",
       "\\end{verbatim}\n",
       "Create a function that compares its argument to \\texttt{x} using \\texttt{≈}, i.e. a function equivalent to \\texttt{y -> y ≈ x}.\n",
       "\n",
       "The keyword arguments supported here are the same as those in the 2-argument \\texttt{isapprox}.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "isapprox(x, y; atol::Real=0, rtol::Real=atol>0 ? 0 : √eps, nans::Bool=false[, norm::Function])\n",
       "```\n",
       "\n",
       "Inexact equality comparison: `true` if `norm(x-y) <= max(atol, rtol*max(norm(x), norm(y)))`. The default `atol` is zero and the default `rtol` depends on the types of `x` and `y`. The keyword argument `nans` determines whether or not NaN values are considered equal (defaults to false).\n",
       "\n",
       "For real or complex floating-point values, if an `atol > 0` is not specified, `rtol` defaults to the square root of [`eps`](@ref) of the type of `x` or `y`, whichever is bigger (least precise). This corresponds to requiring equality of about half of the significand digits. Otherwise, e.g. for integer arguments or if an `atol > 0` is supplied, `rtol` defaults to zero.\n",
       "\n",
       "The `norm` keyword defaults to `abs` for numeric `(x,y)` and to `LinearAlgebra.norm` for arrays (where an alternative `norm` choice is sometimes useful). When `x` and `y` are arrays, if `norm(x-y)` is not finite (i.e. `±Inf` or `NaN`), the comparison falls back to checking whether all elements of `x` and `y` are approximately equal component-wise.\n",
       "\n",
       "The binary operator `≈` is equivalent to `isapprox` with the default arguments, and `x ≉ y` is equivalent to `!isapprox(x,y)`.\n",
       "\n",
       "Note that `x ≈ 0` (i.e., comparing to zero with the default tolerances) is equivalent to `x == 0` since the default `atol` is `0`.  In such cases, you should either supply an appropriate `atol` (or use `norm(x) ≤ atol`) or rearrange your code (e.g. use `x ≈ y` rather than `x - y ≈ 0`).   It is not possible to pick a nonzero `atol` automatically because it depends on the overall scaling (the \"units\") of your problem: for example, in `x - y ≈ 0`, `atol=1e-9` is an absurdly small tolerance if `x` is the [radius of the Earth](https://en.wikipedia.org/wiki/Earth_radius) in meters, but an absurdly large tolerance if `x` is the [radius of a Hydrogen atom](https://en.wikipedia.org/wiki/Bohr_radius) in meters.\n",
       "\n",
       "!!! compat \"Julia 1.6\"\n",
       "    Passing the `norm` keyword argument when comparing numeric (non-array) arguments requires Julia 1.6 or later.\n",
       "\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> 0.1 ≈ (0.1 - 1e-10)\n",
       "true\n",
       "\n",
       "julia> isapprox(10, 11; atol = 2)\n",
       "true\n",
       "\n",
       "julia> isapprox([10.0^9, 1.0], [10.0^9, 2.0])\n",
       "true\n",
       "\n",
       "julia> 1e-10 ≈ 0\n",
       "false\n",
       "\n",
       "julia> isapprox(1e-10, 0, atol=1e-8)\n",
       "true\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "isapprox(x; kwargs...) / ≈(x; kwargs...)\n",
       "```\n",
       "\n",
       "Create a function that compares its argument to `x` using `≈`, i.e. a function equivalent to `y -> y ≈ x`.\n",
       "\n",
       "The keyword arguments supported here are the same as those in the 2-argument `isapprox`.\n"
      ],
      "text/plain": [
       "\u001b[36m  isapprox(x, y; atol::Real=0, rtol::Real=atol>0 ? 0 : √eps, nans::Bool=false[, norm::Function])\u001b[39m\n",
       "\n",
       "  Inexact equality comparison: \u001b[36mtrue\u001b[39m if \u001b[36mnorm(x-y) <= max(atol,\n",
       "  rtol*max(norm(x), norm(y)))\u001b[39m. The default \u001b[36matol\u001b[39m is zero and the default \u001b[36mrtol\u001b[39m\n",
       "  depends on the types of \u001b[36mx\u001b[39m and \u001b[36my\u001b[39m. The keyword argument \u001b[36mnans\u001b[39m determines\n",
       "  whether or not NaN values are considered equal (defaults to false).\n",
       "\n",
       "  For real or complex floating-point values, if an \u001b[36matol > 0\u001b[39m is not specified,\n",
       "  \u001b[36mrtol\u001b[39m defaults to the square root of \u001b[36meps\u001b[39m of the type of \u001b[36mx\u001b[39m or \u001b[36my\u001b[39m, whichever is\n",
       "  bigger (least precise). This corresponds to requiring equality of about half\n",
       "  of the significand digits. Otherwise, e.g. for integer arguments or if an\n",
       "  \u001b[36matol > 0\u001b[39m is supplied, \u001b[36mrtol\u001b[39m defaults to zero.\n",
       "\n",
       "  The \u001b[36mnorm\u001b[39m keyword defaults to \u001b[36mabs\u001b[39m for numeric \u001b[36m(x,y)\u001b[39m and to \u001b[36mLinearAlgebra.norm\u001b[39m\n",
       "  for arrays (where an alternative \u001b[36mnorm\u001b[39m choice is sometimes useful). When \u001b[36mx\u001b[39m\n",
       "  and \u001b[36my\u001b[39m are arrays, if \u001b[36mnorm(x-y)\u001b[39m is not finite (i.e. \u001b[36m±Inf\u001b[39m or \u001b[36mNaN\u001b[39m), the\n",
       "  comparison falls back to checking whether all elements of \u001b[36mx\u001b[39m and \u001b[36my\u001b[39m are\n",
       "  approximately equal component-wise.\n",
       "\n",
       "  The binary operator \u001b[36m≈\u001b[39m is equivalent to \u001b[36misapprox\u001b[39m with the default arguments,\n",
       "  and \u001b[36mx ≉ y\u001b[39m is equivalent to \u001b[36m!isapprox(x,y)\u001b[39m.\n",
       "\n",
       "  Note that \u001b[36mx ≈ 0\u001b[39m (i.e., comparing to zero with the default tolerances) is\n",
       "  equivalent to \u001b[36mx == 0\u001b[39m since the default \u001b[36matol\u001b[39m is \u001b[36m0\u001b[39m. In such cases, you should\n",
       "  either supply an appropriate \u001b[36matol\u001b[39m (or use \u001b[36mnorm(x) ≤ atol\u001b[39m) or rearrange your\n",
       "  code (e.g. use \u001b[36mx ≈ y\u001b[39m rather than \u001b[36mx - y ≈ 0\u001b[39m). It is not possible to pick a\n",
       "  nonzero \u001b[36matol\u001b[39m automatically because it depends on the overall scaling (the\n",
       "  \"units\") of your problem: for example, in \u001b[36mx - y ≈ 0\u001b[39m, \u001b[36matol=1e-9\u001b[39m is an\n",
       "  absurdly small tolerance if \u001b[36mx\u001b[39m is the radius of the Earth\n",
       "  (https://en.wikipedia.org/wiki/Earth_radius) in meters, but an absurdly\n",
       "  large tolerance if \u001b[36mx\u001b[39m is the radius of a Hydrogen atom\n",
       "  (https://en.wikipedia.org/wiki/Bohr_radius) in meters.\n",
       "\n",
       "\u001b[39m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[1mJulia 1.6\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  Passing the \u001b[36mnorm\u001b[39m keyword argument when comparing numeric\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  (non-array) arguments requires Julia 1.6 or later.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> 0.1 ≈ (0.1 - 1e-10)\u001b[39m\n",
       "\u001b[36m  true\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> isapprox(10, 11; atol = 2)\u001b[39m\n",
       "\u001b[36m  true\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> isapprox([10.0^9, 1.0], [10.0^9, 2.0])\u001b[39m\n",
       "\u001b[36m  true\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> 1e-10 ≈ 0\u001b[39m\n",
       "\u001b[36m  false\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> isapprox(1e-10, 0, atol=1e-8)\u001b[39m\n",
       "\u001b[36m  true\u001b[39m\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  isapprox(x; kwargs...) / ≈(x; kwargs...)\u001b[39m\n",
       "\n",
       "  Create a function that compares its argument to \u001b[36mx\u001b[39m using \u001b[36m≈\u001b[39m, i.e. a function\n",
       "  equivalent to \u001b[36my -> y ≈ x\u001b[39m.\n",
       "\n",
       "  The keyword arguments supported here are the same as those in the 2-argument\n",
       "  \u001b[36misapprox\u001b[39m."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?isapprox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now benchmark the C code directly from Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: c_sum not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: c_sum not defined",
      "",
      "Stacktrace:",
      "  [1] var\"##core#259\"(a#258::Vector{Float64})",
      "    @ Main C:\\Users\\anton\\.julia\\packages\\BenchmarkTools\\ms0Xc\\src\\execution.jl:479",
      "  [2] var\"##sample#260\"(__params::BenchmarkTools.Parameters)",
      "    @ Main C:\\Users\\anton\\.julia\\packages\\BenchmarkTools\\ms0Xc\\src\\execution.jl:485",
      "  [3] _run(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters; verbose::Bool, pad::String, kwargs::Base.Iterators.Pairs{Symbol, Integer, NTuple{4, Symbol}, NamedTuple{(:samples, :evals, :gctrial, :gcsample), Tuple{Int64, Int64, Bool, Bool}}})",
      "    @ BenchmarkTools C:\\Users\\anton\\.julia\\packages\\BenchmarkTools\\ms0Xc\\src\\execution.jl:98",
      "  [4] #invokelatest#2",
      "    @ .\\essentials.jl:710 [inlined]",
      "  [5] #run_result#38",
      "    @ C:\\Users\\anton\\.julia\\packages\\BenchmarkTools\\ms0Xc\\src\\execution.jl:33 [inlined]",
      "  [6] run(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters; progressid::Nothing, nleaves::Float64, ndone::Float64, kwargs::Base.Iterators.Pairs{Symbol, Integer, NTuple{5, Symbol}, NamedTuple{(:verbose, :samples, :evals, :gctrial, :gcsample), Tuple{Bool, Int64, Int64, Bool, Bool}}})",
      "    @ BenchmarkTools C:\\Users\\anton\\.julia\\packages\\BenchmarkTools\\ms0Xc\\src\\execution.jl:116",
      "  [7] #warmup#47",
      "    @ C:\\Users\\anton\\.julia\\packages\\BenchmarkTools\\ms0Xc\\src\\execution.jl:168 [inlined]",
      "  [8] warmup(item::BenchmarkTools.Benchmark)",
      "    @ BenchmarkTools C:\\Users\\anton\\.julia\\packages\\BenchmarkTools\\ms0Xc\\src\\execution.jl:168",
      "  [9] top-level scope",
      "    @ C:\\Users\\anton\\.julia\\packages\\BenchmarkTools\\ms0Xc\\src\\execution.jl:387",
      " [10] eval",
      "    @ .\\boot.jl:360 [inlined]",
      " [11] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "c_bench = @benchmark c_sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: c_bench not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: c_bench not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[17]:1",
      " [2] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "println(\"C: Fastest time was $(minimum(c_bench.times) / 1e6) msec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: c_bench not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: c_bench not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[24]:2",
      " [2] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "d = Dict()  # a \"dictionary\", i.e. an associative array\n",
    "d[\"C\"] = minimum(c_bench.times) / 1e6  # in milliseconds\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "gr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics # bring in statistical support for standard deviations\n",
    "t = c_bench.times / 1e6 # times in milliseconds\n",
    "m, σ = minimum(t), std(t)\n",
    "\n",
    "histogram(t, bins=500,\n",
    "    xlim=(m - 0.01, m + σ),\n",
    "    xlabel=\"milliseconds\", ylabel=\"count\", label=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. C with -ffast-math\n",
    "\n",
    "If we allow C to re-arrange the floating point operations, then it'll vectorize with SIMD (single instruction, multiple data) instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const Clib_fastmath = tempname()   # make a temporary file\n",
    "\n",
    "# The same as above but with a -ffast-math flag added\n",
    "open(`gcc -fPIC -O3 -msse3 -xc -shared -ffast-math -o $(Clib_fastmath * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code) \n",
    "end\n",
    "\n",
    "# define a Julia function that calls the C function:\n",
    "c_sum_fastmath(X::Array{Float64}) = ccall((\"c_sum\", Clib_fastmath), Float64, (Csize_t, Ptr{Float64}), length(X), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_fastmath_bench = @benchmark $c_sum_fastmath($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"C -ffast-math\"] = minimum(c_fastmath_bench.times) / 1e6  # in milliseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Python's built in `sum` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PyCall` package provides a Julia interface to Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Pkg; Pkg.add(\"PyCall\")\n",
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <built-in function sum>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the Python built-in \"sum\" function:\n",
    "pysum = pybuiltin(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.000566333320858e6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pysum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pysum(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  336 bytes\n",
       "  allocs estimate:  6\n",
       "  --------------\n",
       "  minimum time:     746.899 ms (0.00% GC)\n",
       "  median time:      769.583 ms (0.00% GC)\n",
       "  mean time:        775.178 ms (0.00% GC)\n",
       "  maximum time:     827.033 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          7\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_list_bench = @benchmark $pysum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 1 entry:\n",
       "  \"Python built-in\" => 746.899"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Python built-in\"] = minimum(py_list_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Python: `numpy` \n",
    "\n",
    "## Takes advantage of hardware \"SIMD\", but only works when it works.\n",
    "\n",
    "`numpy` is an optimized C library, callable from Python.\n",
    "It may be installed within Julia as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "using Pkg; Pkg.add(\"Conda\")\n",
    "using Conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y numpy` in root environment\n",
      "└ @ Conda C:\\Users\\anton\\.julia\\packages\\Conda\\sNGum\\src\\Conda.jl:128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Conda.add(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  336 bytes\n",
       "  allocs estimate:  6\n",
       "  --------------\n",
       "  minimum time:     11.914 ms (0.00% GC)\n",
       "  median time:      13.624 ms (0.00% GC)\n",
       "  mean time:        14.135 ms (0.00% GC)\n",
       "  maximum time:     19.970 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          353\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum = pyimport(\"numpy\")[\"sum\"]\n",
    "\n",
    "py_numpy_bench = @benchmark $numpy_sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.000566333321071e6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 2 entries:\n",
       "  \"Python numpy\"    => 11.9137\n",
       "  \"Python built-in\" => 746.899"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Python numpy\"] = minimum(py_numpy_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Python, hand-written "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <function py_sum at 0x000000000E064A60>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py\"\"\"\n",
    "def py_sum(A):\n",
    "    s = 0.0\n",
    "    for a in A:\n",
    "        s += a\n",
    "    return s\n",
    "\"\"\"\n",
    "\n",
    "sum_py = py\"py_sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  336 bytes\n",
       "  allocs estimate:  6\n",
       "  --------------\n",
       "  minimum time:     938.084 ms (0.00% GC)\n",
       "  median time:      964.783 ms (0.00% GC)\n",
       "  mean time:        978.616 ms (0.00% GC)\n",
       "  maximum time:     1.092 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          6\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_hand = @benchmark $sum_py($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.000566333320858e6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_py(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_py(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 3 entries:\n",
       "  \"Python numpy\"        => 11.9137\n",
       "  \"Python hand-written\" => 938.084\n",
       "  \"Python built-in\"     => 746.899"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Python hand-written\"] = minimum(py_hand.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Julia (built-in) \n",
    "\n",
    "## Written directly in Julia, not in C!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "sum(a::<b>AbstractArray</b>; <i>dims, kw...</i>) in Base at <a href=\"https://github.com/JuliaLang/julia/tree/6aaedecc447e3d8226d5027fb13d0c3cbfbfea2a/base/reducedim.jl#L873\" target=\"_blank\">reducedim.jl:873</a>"
      ],
      "text/plain": [
       "sum(a::AbstractArray; dims, kw...) in Base at reducedim.jl:873"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@which sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     4.190 ms (0.00% GC)\n",
       "  median time:      4.939 ms (0.00% GC)\n",
       "  mean time:        5.144 ms (0.00% GC)\n",
       "  maximum time:     7.963 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          968\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench = @benchmark sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 4 entries:\n",
       "  \"Python numpy\"        => 11.9137\n",
       "  \"Python hand-written\" => 938.084\n",
       "  \"Python built-in\"     => 746.899\n",
       "  \"Julia built-in\"      => 4.1896"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Julia built-in\"] = minimum(j_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Julia (hand-written) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum (generic function with 1 method)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum(A)   \n",
    "    s = 0.0 # s = zero(eltype(a))\n",
    "    for a in A\n",
    "        s += a\n",
    "    end\n",
    "    s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     12.268 ms (0.00% GC)\n",
       "  median time:      13.332 ms (0.00% GC)\n",
       "  mean time:        13.565 ms (0.00% GC)\n",
       "  maximum time:     25.836 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          368\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench_hand = @benchmark mysum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 5 entries:\n",
       "  \"Python numpy\"        => 11.9137\n",
       "  \"Julia hand-written\"  => 12.2678\n",
       "  \"Python hand-written\" => 938.084\n",
       "  \"Python built-in\"     => 746.899\n",
       "  \"Julia built-in\"      => 4.1896"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Julia hand-written\"] = minimum(j_bench_hand.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Julia (hand-written w. simd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum_simd (generic function with 1 method)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum_simd(A)   \n",
    "    s = 0.0 # s = zero(eltype(A))\n",
    "    @simd for a in A\n",
    "        s += a\n",
    "    end\n",
    "    s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     4.221 ms (0.00% GC)\n",
       "  median time:      5.157 ms (0.00% GC)\n",
       "  mean time:        5.392 ms (0.00% GC)\n",
       "  maximum time:     12.069 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          923\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench_hand_simd = @benchmark mysum_simd($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.000566333321078e6"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysum_simd(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 6 entries:\n",
       "  \"Julia hand-written simd\" => 4.2215\n",
       "  \"Python numpy\"            => 11.9137\n",
       "  \"Julia hand-written\"      => 12.2678\n",
       "  \"Python hand-written\"     => 938.084\n",
       "  \"Python built-in\"         => 746.899\n",
       "  \"Julia built-in\"          => 4.1896"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Julia hand-written simd\"] = minimum(j_bench_hand_simd.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia built-in..............4.2\n",
      "Julia hand-written simd.....4.2\n",
      "Python numpy...............11.9\n",
      "Julia hand-written.........12.3\n",
      "Python built-in...........746.9\n",
      "Python hand-written.......938.1\n"
     ]
    }
   ],
   "source": [
    "for (key, value) in sort(collect(d), by=last)\n",
    "    println(rpad(key, 25, \".\"), lpad(round(value; digits=1), 6, \".\"))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1md\u001b[22m mac\u001b[0m\u001b[1mr\u001b[22moex\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1ma\u001b[22mn\u001b[0m\u001b[1md\u001b[22m @mac\u001b[0m\u001b[1mr\u001b[22moex\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1ma\u001b[22mn\u001b[0m\u001b[1md\u001b[22m @mac\u001b[0m\u001b[1mr\u001b[22moex\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1ma\u001b[22mn\u001b[0m\u001b[1md\u001b[22m1 isdi\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1ma\u001b[22mth t\u001b[0m\u001b[1mr\u001b[22my\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1ma\u001b[22mrse no\u001b[0m\u001b[1mr\u001b[22mm\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1ma\u001b[22mth\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "rpad(s, n::Integer, p::Union{AbstractChar,AbstractString}=' ') -> String\n",
       "\\end{verbatim}\n",
       "Stringify \\texttt{s} and pad the resulting string on the right with \\texttt{p} to make it \\texttt{n} characters (code points) long. If \\texttt{s} is already \\texttt{n} characters long, an equal string is returned. Pad with spaces by default.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> rpad(\"March\", 20)\n",
       "\"March               \"\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "rpad(s, n::Integer, p::Union{AbstractChar,AbstractString}=' ') -> String\n",
       "```\n",
       "\n",
       "Stringify `s` and pad the resulting string on the right with `p` to make it `n` characters (code points) long. If `s` is already `n` characters long, an equal string is returned. Pad with spaces by default.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> rpad(\"March\", 20)\n",
       "\"March               \"\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  rpad(s, n::Integer, p::Union{AbstractChar,AbstractString}=' ') -> String\u001b[39m\n",
       "\n",
       "  Stringify \u001b[36ms\u001b[39m and pad the resulting string on the right with \u001b[36mp\u001b[39m to make it \u001b[36mn\u001b[39m\n",
       "  characters (code points) long. If \u001b[36ms\u001b[39m is already \u001b[36mn\u001b[39m characters long, an equal\n",
       "  string is returned. Pad with spaces by default.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> rpad(\"March\", 20)\u001b[39m\n",
       "\u001b[36m  \"March               \"\u001b[39m"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?rpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "212px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "2",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
